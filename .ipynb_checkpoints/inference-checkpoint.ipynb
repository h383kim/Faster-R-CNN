{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab7ca9f-0d72-45c7-9faf-8f41e9cc3f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def infer(model, img_path, device=device):\n",
    "    model.eval()\n",
    "    # Load Image\n",
    "    image = Image.open(img_path)\n",
    "    transform = transforms.ToTensor()\n",
    "    image = transform(image).to(device)\n",
    "    \n",
    "    # Feed to model\n",
    "    rpn_output, roi_detector_output = model(image, None)\n",
    "    final_boxes = roi_detector_output['bboxes']\n",
    "    final_scores = roi_detector_output['scores']\n",
    "    final_labels = roi_detector_output['labels'].to(torch.int32)\n",
    "    return final_boxes, final_scores, final_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01502be4-ab37-4a7e-bf44-f9cab5f23c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def draw_gtbboxes(img_path, anno_path, proposals, scores, labels):\n",
    "    image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    tree = ET.parse(anno_path)\n",
    "    root = tree.getroot()\n",
    "    gt_bboxes = parse_xml_boxes(root)\n",
    "\n",
    "    # Draw GT bounding boxes\n",
    "    for bbox in gt_bboxes:\n",
    "        xmin, ymin, xmax, ymax = bbox[0], bbox[1], bbox[2], bbox[3]\n",
    "        image = cv2.rectangle(image, (xmin, ymin), (xmax, ymax), color=(0, 255, 0), thickness=2)\n",
    "\n",
    "    fig, ax = plt.subplots(1)\n",
    "    ax.imshow(image)\n",
    "\n",
    "    proposals = proposals.cpu()\n",
    "    # Draw proposal bounding boxes\n",
    "    for idx, bbox in enumerate(proposals):\n",
    "        x_min, y_min, width, height = bbox[0], bbox[1], bbox[2] - bbox[0], bbox[3] - bbox[1]\n",
    "        rect = plt.Rectangle((x_min, y_min), width, height, linewidth=2, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(x_min, y_min, f\"{VOC_CLASSES[labels[idx]]} : {scores[idx]:.2f}\", fontsize=6, bbox=dict(facecolor='yellow', alpha=1))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b42b30-8a3b-4600-92c5-4954ab9c9fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "faster_rcnn = FasterRCNN()\n",
    "faster_rcnn.load_state_dict(torch.load(r\".\\model.pth\", map_location=torch.device(\"cpu\")))\n",
    "faster_rcnn = faster_rcnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daa6667-01db-43b9-abe4-43e7041a8fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '/kaggle/input/pascal-voc-2007/VOCtrainval_06-Nov-2007/VOCdevkit/VOC2007/JPEGImages/000007.jpg'\n",
    "anno_path = '/kaggle/input/pascal-voc-2007/VOCtrainval_06-Nov-2007/VOCdevkit/VOC2007/Annotations/000007.xml'\n",
    "boxes, scores, labels = infer(faster_rcnn, img_path)\n",
    "print(f\"final boxes: {boxes}\")\n",
    "print(f\"final scores: {scores}\")\n",
    "print(f\"final labels: {labels}\")\n",
    "draw_gtbboxes(img_path, anno_path, boxes, scores, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env)",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
